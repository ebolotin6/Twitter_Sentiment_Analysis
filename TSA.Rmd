---
title: "Twitter_Sentiment_Analysis"
author: "Eli (Ilya) Bolotin"
date: "11/18/2018"
output: pdf_document
header-includes:
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries

```{r cars}
library(dplyr)
library(ggplot2)
```

This data has been procured and cleaned in Python and is ready for analysis. We are only concerned with the sentiment scores produces by NLTK's VADER algorithm (and not those from TextBlob, which have also been computed in this data).

## First, let's read in data for both groups: tweets of people who talk about fitness and people who talk about media.

```{r, echo=FALSE}
# IMPORTANT: change working dir
setwd('Samples_Round_1/')

# read in csvs of both sample groups
group_1 <- read.csv("streamed_tweets_fitness_clean_full_analysis.csv", header=TRUE, sep=",")
group_2 <- read.csv("streamed_tweets_media_clean_full_analysis.csv", header=TRUE, sep=",")

```
## Next, we need to two things. The first is to label each group. The second is to exclude users that appear in both groups.

```{r, echo=FALSE}

# Add column to both datasets to label each group and convert group to factor
group_1 = mutate(group_1, group = "fitness")
group_1 = mutate(group_1, group = as.factor(group))
group_2 = mutate(group_2, group = "media")
group_2 = mutate(group_2, group = as.factor(group))

# create list to exclude users that appear in both lists
excluded_users <- list()

i = 1
for(user_id in group_1$user_id) {
  if(user_id %in% group_2$user_id) {
    excluded_users[[i]] <- user_id
    i = i + 1
  }
}

excluded_users <- unique(excluded_users)

group_1 <- group_1[!(group_1$user_id %in% excluded_users),]
group_2 <- group_2[!(group_2$user_id %in% excluded_users),]

```

## Next, we need to ensure that our sample sizes are the same for both groups. The problem is that these groups have different numbers of tweets, and thus the samples vary. But we need the sample size to be the same so that we can accurately gauge sentiment. To do this, we will generate random numbers specific to the index range of each group, and then take 5000 random indices of each group. These 5000 indices (randomly generated for each group) will constitute our sample size of 5000 tweets.

```{r, echo=FALSE}

# select sample sizes and possible ranges to generate indices
n <- 9700
group_1_index_range <- nrow(group_1)
group_2_index_range <- nrow(group_2)

# for group 1: generate indices of random sample
set.seed(1)
sample_indices_group_1 <- sample(1:group_1_index_range, n, replace = FALSE)
sample_indices_group_1 <- sort(sample_indices_group_1)

# for group 2: generate indices of random sample
sample_indices_group_2 <- sample(1:group_2_index_range, n, replace = FALSE)
sample_indices_group_2 <- sort(sample_indices_group_2)

# select tweets by sample index
group_1 <- group_1[sample_indices_group_1, c("group","sentiment_vader")]
group_2 <- group_2[sample_indices_group_2, c("group","sentiment_vader")]

```

## Finally, we combine both groups into a single dataframe for analysis.

```{r, echo=FALSE}

# combine groups into one dataframe
combined_df = rbind(group_1, group_2)

```

## With our data prepared - we verify the group sizes for both samples.

```{r, echo=FALSE}
group_size <- combined_df %>%
    group_by(group) %>%
    dplyr::summarize(
      group_size = n()
      )

group_size
```

The fitness group for this sample is nearly 70% bigger than the media group. But, how do their distributions compare? Let's check below.

## Plot boxplot of sentiment scores to see distribution stats.

```{r, echo=FALSE}

ggplot(combined_df, aes(x = group, y = sentiment_vader)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
  ggtitle("Distribution of sentiment by group") + xlab("Group") + ylab("(VADER) Sentiment")

```

The distributions of both groups are also quite similar. However, the fitness group has a higher interquartile range. This means that the fitness group has tweets with a higher sentiment than the media group at the 3rd quartile. Another observation is that the first quartile (for both groups) ends nearly on the median. This tells us that a majority of the sentiments less than zero are very close to zero. Meaning, the spread is skewed towards a sentiment of zero.

# However, the boxplot above does not give us much more information because the median for both groups is the same. Let's review summary statistics of both groups to get a sense of scale. 

```{r, echo=FALSE}

summary_stats <- combined_df %>%
    group_by(group) %>%
    dplyr::summarize(
      group_size = n(),
      equal_to_0 = length(sentiment_vader[sentiment_vader == 0]),
      above_0 = length(sentiment_vader[sentiment_vader > 0]),
      below_0 = length(sentiment_vader[sentiment_vader < 0])
      )

summary_stats

```

We notice that for the fitness group, ~86% of tweets are equal to or above 0 (neutral) sentiment. For the media group, this number is ~85%. The conclusion for both groups is that tweets are overwhelmingly neutral and/or positive in sentiment.

## Next, let's visualize the distribution above. We can do this by plotting a density plot and histogram of the (VADER) sentiment scores to see the frequency of sentiments.
```{r, echo=FALSE}

# Density plots
qplot(sentiment_vader, data=combined_df, geom="density", fill=group, alpha=I(.5), 
   main="Sentiment Distribution", xlab="(VADER) Sentiment Distribution", 
   ylab="Density")

# Histogram
ggplot(combined_df, aes(sentiment_vader, fill = group)) +
  geom_histogram(position="identity", alpha = .5) + ggtitle("Distribution of sentiment")

```

The density and histogram plots tell us a few things clearly:
1. The sentiments for both groups do not quite follow a normal distribution **at this sample size**.
1. Both groups have a very similar distribution of sentiments. Meaning, people in both groups tend to express themselves similarly in sentiment. 
2. Another insight is that the most common sentiment is neutral (equal to 0), or close to it.
3. There are **more** positive sentiments (greater than 0) than there are negative sentiments.
4. The fitness group has a higher frequency of positive sentiments than the media group.

## Given the density distribution, let's check if both samples follow a normal distribution:

```{r, echo=FALSE}

# define groups
fitness_group = combined_df$sentiment_vader[combined_df$group == 'fitness']
media_group = combined_df$sentiment_vader[combined_df$group == 'media']

# Q-Q Plot for fitness group
qqnorm(fitness_group, pch = 1, frame = FALSE)
qqline(fitness_group, col = "blue", lwd = 2)

# Q-Q plot for media group
qqnorm(media_group, pch = 1, frame = FALSE)
qqline(media_group, col = "blue", lwd = 2)

```
The Q-Q plot confirms that the sentiment from our sample groups does not follow a normal distribution. This means that parametric statistics tests such as the T-Test may not be ideally suited to determine if one group is statistically different from another. This is because parametric statistics tests make assumptions about "about the parameters (defining properties) of the population distribution from which one's data are drawn" [1]. Because we cannot assume the data to be symmetrical about the mean (or equal variance, among other differences), it is probably not ideal to depend on these parametric tests.

[1] Parametric vs Non-parametric, http://vassarstats.net/textbook/parametric.html

## Let's compute summary statistics for both groups to determine key metrics.

```{r, echo=FALSE}

# compute statistical summary for both groups
stat_summary <- combined_df %>%
    group_by(group) %>%
    dplyr::summarize(
      group_size = n(),
      median_sentiment = median(sentiment_vader),
      mean.sentiment = mean(sentiment_vader),
      sd.sentiment = sd(sentiment_vader),
      se.mean.sentiment = sd.sentiment / sqrt(group_size)
      )

stat_summary

```

The median sentiment between both groups is the same (0). However, the mean sentiment appears statistically different. SD and SE are also different between both samples.

## Although Welch's test is a parametric test (and thus not ideally suited for this hypothesis test), let's run this test as a point of reference to determine if the means of both groups are significantly different.

```{r, echo=FALSE}

t.test <- t.test(sentiment_vader ~ group, var.equal = FALSE, data = combined_df)
t.test

```

The T-test confirms that the mean's of both groups are statistically significant. This would suggest that we can reject the null hypothesis that people that talk about fitness are equally happy as people that talk about media. 

However, can we trust this test given that our small sample sizes and the fact that the data does not follow a standard normal distribution?

## To find out how reliable this conclusion is, let's run the Mann-Whitney U test (also known as the Wilcox test). It is a nonparametric of the null hypothesis designed to account for non-normal distributions.

```{r, echo=FALSE}

wilcox.test <- wilcox.test(sentiment_vader ~ group, data = combined_df, conf.int=TRUE, alternative = "greater")
wilcox.test

```

The Wilcox test confirms the T-Test of unequal variances, leading us to conclude that the NULL hypothesis should be rejected and that there is a significant difference in happiness between individuals that discuss fitness and those that discuss media.

## Another nonparametric test that we can use to check whether our samples originate from the same distribution is the Kruskal Wallis test [2], which compares/analyzes the medians of two independent samples. Being nonparametric, this test does not assume that our samples have equal variance or are normally distributed. The KW analysis will do well to tell us if the medians of both samples are statistically significantly different, and thus if we can reject the null hypothesis.

[2] Kruskal-Wallis Test, https://en.wikipedia.org/wiki/Kruskalâ€“Wallis_one-way_analysis_of_variance

```{r, echo=FALSE}

k.test <- kruskal.test(sentiment_vader ~ group, data = combined_df)
k.test

```

In this test, the p-value is smaller than our significance level of 0.05. As a result, we must reject our NULL hypothesis that people that discuss fitness are equally happy as people that discuss media.

