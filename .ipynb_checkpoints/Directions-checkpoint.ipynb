{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Program\n",
    "#### Eli Bolotin\n",
    "##### Copyright 2018, All Rights Reserved.\n",
    "\n",
    "*Important* Make sure that the files for this program are in your parent directory.\n",
    "\n",
    "## Program (usage) Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open file StreamTweets.py\n",
    "\n",
    "1. (Step 1) Define list of keywords and hashtags for each group.\n",
    "2. (Step 2) Stream tweets for group 1 and 2 (Python step)\n",
    "    \n",
    "#### Step 2 function explanation: \n",
    "\n",
    "Example:\n",
    "##### stream_tweets(keywords_m, option = 'user_info', file_name = 'streamed_tweets_media', max_tweets = 5000)\n",
    "\n",
    "Function arguments:\n",
    "* **option**: argument must be 'user_info'\n",
    "* **file_name**: define the name of the file to dump the tweets in JSON format. **Do not include extension**\n",
    "* **max_tweets**: define number of tweets to stream. \n",
    "* **Function output**: json and csv files of streamed tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterProgram import MyStreamListener, stream_tweets\n",
    "\n",
    "### Step 1: define keywords and hashtags for media group\n",
    "keywords_m = ['watching show','watch season','netflix','movie','new season','watching tv','binge watching','newseries','new episode','prime video','dvr','atthemovies','film','horror','comedy','thriller','shortfilm','firstseason','secondseason','thirdseason','fourthseason','fithseason','lastseason','#watchingshow','#watchseason','#newseason','#watchingtv','#bingewatching','#newepisode','#primevideo','#edgeofmyseat','#nbc','#abc','#disney','#cnbc','#cbs','#primetime','#waitedsolong','#comedycentral']\n",
    "\n",
    "### Step 1: define keywords and hashtags for fitness group\n",
    "keywords_f = ['health fitness','fitness','legday','workoutwednesday','treadmill','pilates','yoga','gym time','deadlift','squats','FitnessFriday','gymlife','workouts','fitness training','postgym','armday','shoulderday','fitnessgoals','runner','workout','workout motivation','lift hard','lift weight','go running','crossfit','morning workout','muscle','six pack','lunges','cardio','elliptical','cycling','#health','#gymtime','#fitnesstraining','#workoutmotivation','#lifthard','#liftweight','#gorunning','#sweatforit','#morningworkout','#sixpack','#triathlon']\n",
    "\n",
    "### step 2: stream tweets for media group\n",
    "file_name_m = stream_tweets(keywords_m, option = 'user_info', file_name = 'streamed_tweets_media', max_tweets = 5000)\n",
    "\n",
    "### step 2: stream tweets for athletic group\n",
    "file_name_a = stream_tweets(keywords_f, option = 'user_info', file_name = 'streamed_tweets_fitness', max_tweets = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open file: ProcessTweets.py\n",
    "\n",
    "3. (Step 3) Clean the streamed tweets via program algorithm (Python step). Afterwards, examine the cleaned tweets.\n",
    "\t- input: json file\n",
    "\t- returns: csv file\n",
    "\t- file output: csv file\n",
    "\n",
    "4. (Step 4) Fetch other (non-filtered) tweets in full data format. Store the full data, but present the user with a column-truncated version for readability.\n",
    "\t- input: csv file\n",
    "\t- returns: json\n",
    "\t- output: csv and json\n",
    "\n",
    "5. (Step 5) Generate sentiment for tweets.\n",
    "\t- input: json file\n",
    "\t- returns: csv\n",
    "\t- output: csv\n",
    "    \n",
    "6. (Step 6) Conduct statistical analysis in R.\n",
    "\n",
    "#### Step 3 function explanation (using example): \n",
    "\n",
    "##### group_1 = StreamedTweets(\"streamed_tweets_media.json\", sub_dir=\"Samples_Round_1\")\n",
    "    Function arguments:\n",
    "    * **first arg**: enter **json** file_name including extension\n",
    "    * **sub_dir**: enter sub directory containing filename\n",
    "\n",
    "##### group_1.clean_tweets()\n",
    "    Function arguments: None\n",
    "\n",
    "#### Step 4 function explanation (using example): \n",
    "\n",
    "##### group_1.get_full_tweets(max_users = 3000)\n",
    "    Function arguments:\n",
    "    * **max_users**: number of users to fetch from the top of the streamed tweets file\n",
    "    \n",
    "#### Step 5 function explanation (using example): \n",
    "\n",
    "##### group_1.get_sentiment()\n",
    "    Function arguments: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterProgram import StreamedTweets, TweetProgram\n",
    "\n",
    "### step 1 and 2: stream tweets (using StreamTweets.py)\n",
    "### step 3 instantiate object and clean tweets\n",
    "group_1 = StreamedTweets(\"streamed_tweets_media.json\", sub_dir=\"Samples_Round_2\")\n",
    "group_1.clean_tweets()\n",
    "\n",
    "### step 4: fetch other tweets\n",
    "group_1.get_full_tweets(max_users = 3000)\n",
    "\n",
    "### step 5 - produce sentiment analysis of cleaned tweets. \n",
    "group_1.get_sentiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3_venv",
   "language": "python",
   "name": "py3_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
