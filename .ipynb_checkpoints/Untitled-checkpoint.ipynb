{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directions\n",
    "\n",
    "## Open file StreamTweets.py\n",
    "\n",
    "1. Define list of keywords and hashtags for each group.\n",
    "2. (Step 1) Stream tweets for group 1 and 2 (Python step)\n",
    "    - example: stream_tweets(workout_keyterms, option = 'user_info', file_name = 'streamed_tweets_workout', num_users = 2000)\n",
    "    - Examine 'streamed_tweets_workout' to review 2000 tweets (manual step).\n",
    "    - input: none\n",
    "    - returns: json filename\n",
    "    - creates: json file and csv file\n",
    "\n",
    "## Open file: ProcessTweets.py\n",
    "\n",
    "3. (Step 2) Clean the streamed tweets via program algorithm (Python step)\n",
    "\t- example: clean_tweets(\"streamed_tweets_workout.json\")\n",
    "\t- Examine cleaned tweets and make changes if necessary.\n",
    "\t- input: json \n",
    "\t- returns: csv file for streamed tweets\n",
    "\t- output: csv file for streamed tweets\n",
    "\n",
    "4. (Step 3) Fetch other tweets in full data format for users in streamed groups of tweets (Python step). Store the full data, but present the user with a column-truncated version for readability.\n",
    "\t- example: get_full_tweets('streamed_tweets_workout.csv')\n",
    "\t- Examine the truncated tweets to review fetched tweets (manual step)\n",
    "\t- input: csv\n",
    "\t- returns: json\n",
    "\t- output: csv and json\n",
    "\n",
    "    (OPTIONAL) Clean the fetched & truncated tweets via algorithm (Python step)\n",
    "    - clean_tweets(\"streamed_tweets_workout_clean_truncated.json\", tweets_type = \"REST\")\n",
    "    - input: json\n",
    "    - returns: json\n",
    "    - output: csv and json\n",
    "\n",
    "5. (Step 4) Generate sentiment for tweets\n",
    "\t- input: json\n",
    "\t- returns: csv\n",
    "\t- output: csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Sentiment Analysis Program\n",
    "# Eli Bolotin\n",
    "# Copyright 2018, All Rights Reserved.\n",
    "\n",
    "from TwitterProgram import StreamedTweets, TweetProgram\n",
    "\n",
    "######### Group 1 #########\n",
    "\n",
    "### step 1 stream tweets (using StreamTweets.py)\n",
    "### step 2 instantiate object and clean tweets\n",
    "group_1 = StreamedTweets(\"streamed_tweets_media.json\", sub_dir=\"Samples_Round_2\")\n",
    "group_1.clean_tweets()\n",
    "\n",
    "### step 3: fetch other tweets\n",
    "group_1.get_full_tweets(max_users = 3000)\n",
    "\n",
    "### step 4: clean the fetched tweets\n",
    "group_1.clean_tweets(tweets_type = \"full\")\n",
    "\n",
    "### step 5 - produce sentiment analysis of cleaned tweets. Remember, we are cleaning the full file, not the truncated version (which is the same as the full file, only less columns for readability).\n",
    "group_1.get_sentiment()\n",
    "\n",
    "######### Group 2 #########\n",
    "\n",
    "### step 1 stream tweets (using StreamTweets.py)\n",
    "### step 2 instantiate object and clean tweets\n",
    "group_2 = StreamedTweets(\"streamed_tweets_fitness.json\", sub_dir=\"Samples_Round_2\")\n",
    "group_2.clean_tweets()\n",
    "\n",
    "### step 3: fetch other tweets\n",
    "group_2.get_full_tweets(max_users = 3000)\n",
    "\n",
    "### step 4: clean the fetched tweets\n",
    "group_2.clean_tweets(tweets_type = \"full\")\n",
    "\n",
    "### step 5 - produce sentiment analysis of cleaned tweets. Remember, we are cleaning the full file, not the truncated version (which is the same as the full file, only less columns for readability).\n",
    "group_2.get_sentiment()\n",
    "\n",
    "(using StreamTweets.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3_venv",
   "language": "python",
   "name": "py3_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
